<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Generative Hypergraph Clustering:   Scalable Heuristics and Sparse Thresholds</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr. Phil Chodrow   Department of Mathematics   University of California, Los Angeles" />
    <link rel="stylesheet" href="../assets/ninpo.css" type="text/css" />
    <link rel="stylesheet" href="../assets/ninjutsu.css" type="text/css" />
    <link rel="stylesheet" href="../assets/shinobi.css" type="text/css" />
    <link rel="stylesheet" href="../assets/pc_custom.css" type="text/css" />
    <link rel="stylesheet" href="css/pc_custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Generative Hypergraph Clustering: <br> Scalable Heuristics and Sparse Thresholds
## Department of Mathematics and Computer Science <br> Wesleyan University<br> January 13th, 2022
### Dr. <span class="author-highlight">Phil Chodrow</span> <br> Department of Mathematics <br> University of California, Los Angeles

---

exclude: true   
&lt;style type="text/css"&gt;
code.r{ 
  font-size: 16px; 
}
pre {
  font-size: 16px !important;  
}
&lt;/style&gt;






---

class: split-two 

.column.bg-main1[.content[

### Hi! I'm Phil Chodrow.

&lt;br&gt;

Things I .alert[like]:]

- Computation and theory for complex systems
  - Network data analysis
  - Models social systems
  - Machine learning
- Data science and social justice
- Tea
- *Star Trek: Deep Space 9*  
- Traditional martial arts
]

.column[.content.center[&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; 
&lt;img src="img/phil.jpg" width=80%&gt;]


]





---

class: bg-main1 
background-image: url("../img-shared/geo-intro.png")
background-size: contain
 
# My Journey
 



---

class: split-two
layout: false

.column.bg-main1[
.content[ 
  ## Graphs and Hypergraphs 
 
  &lt;br&gt; 
  A .alert[graph] consists of a set of nodes and a set of edges. Each edge is a set of two nodes. 

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;
  In .alert[hypergraphs], edges can contain *any number* of nodes.     
]
]

.column[
  .vmiddle[
  &lt;img src="img/graph-hypergraph.png" width=100%&gt;&lt;/img&gt;
  ] 
]

---

class: split-two
layout: false

.column.bg-main1[
  
## Hypergraph Data

]

.column.bg-main2[.vmiddle[
  &lt;br&gt;
]]

---

class: split-two
layout: false

.column.bg-main1[
  
  ## Hypergraph Data

&lt;br&gt; &lt;br&gt; 

  - .alert[**Interaction**]: nodes are agents, edges are interaction events (socializing in groups, attending events).
  
]

.column.bg-main2[.vmiddle[.stretch[
  &lt;img src="img/social-interaction.jpeg" width=100%&gt;&lt;/img&gt; 
]]]

---

class: split-two
layout: false

.column.bg-main1[
  
  ## Hypergraph Data

&lt;br&gt; &lt;br&gt; 

  - .alert[**Interaction**]: nodes are agents, edges are interaction events (socializing in groups, attending events).
  - .alert[**Collaboration**]: nodes are collaborators, edges are projects or teams (scholarly papers, legislation, etc). 
  

]

.column.bg-main2[.vmiddle[.stretch[
  &lt;img src="img/teamwork.jpeg" width=100%&gt;&lt;/img&gt; 
]]]

---

class: split-two
layout: false

.column.bg-main1[
  
  ## Hypergraph Data

&lt;br&gt; &lt;br&gt; 

  - .alert[**Interaction**]: nodes are agents, edges are interaction events (socializing in groups, attending events).
  - .alert[**Collaboration**]: nodes are collaborators, edges are projects or teams (scholarly papers, legislation, etc). 
  - .alert[**Co-presence**]: nodes are chemical compounds, edges are drugs formed from those compounds.

]

.column.bg-main2[.vmiddle[.stretch[
  &lt;img src="img/mccoy.png" width=100%&gt;&lt;/img&gt; 
]]]

---

layout: false
class: split-two

.column.bg-main1[
  ### The Hypergraph Clustering Task

  &lt;br&gt;
  Given some hypergraph data, assign each node to a .alert[**cluster**] (or "community") of "related" nodes. 
  &lt;br&gt; &lt;br&gt;
  "*Related*": often interpreted as "*densely interconnected.*"
&lt;br&gt; &lt;br&gt;
  Applications in social network analysis, drug discovery, image processing, data visualization...

  
  .footnote[
  .alert2[One survey in]: &lt;br&gt; &lt;b&gt;PSC&lt;/b&gt;, N. Veldt, A. R. Benson, (2021). Generative hypergraph clustering: from blockmodels to modularity, &lt;i&gt;Science Advances&lt;/i&gt;, 7:eabh1303
  ]

  
]
.column[.content.vmiddle[.stretch[
  &lt;img src="img/detection-1.png" width=100%&gt;
]]]


---

layout: true
class: split-two middle 
 
.column[
  .split-three[ 
  .row.bg-main1[.content.vmiddle[.font_medium[Generative clustering with .alert[hypergraph blockmodels]].
  ]]    
  .row.bg-main2[.content.vmiddle[.font_medium[Scalable, greedy heuristics for .alert[large hypergraphs].] 
  ]] 
  .row.bg-main3[.content.vmiddle[.font_medium[.alert[Sparse thresholds] and eigenvector methods.] 
  ]]
]
] 

.column[.center[.stretch[
  {{content}} 
]]]

---
class: hide-row2-col1 hide-row3-col1 hide-row4-col1 hide-row5-col1 

&lt;br&gt;
&lt;img src="img/pure-fiction.png" width=100%&gt;

---
class: hide-row3-col1 hide-row4-col1 hide-row5-col1


&lt;img src="img/contact-clustering-excerpt.png" width=100%&gt;

  
---
class: hide-row4-col1   hide-row5-col1 

&lt;img src="img/spectrum.png" width=75%&gt; 
&lt;img src="img/heatmap-exp-1.png" width=85%&gt; 

---

class: fade-row2-col1 fade-row3-col1 fade-row4-col1 fade-row5-col1

  &lt;br&gt;
  &lt;img src="img/pure-fiction.png" width=100%&gt;

---

layout: false
background-image: url(img/task.png)
background-size: contain

---

layout: false
background-image: url(img/fiction.png)
background-size: contain


---

class: split-two
layout: false

.column[ 
  ### Hypergraph Stochastic Blockmodel
  &lt;img src="img/pure-fiction.png" width=90%&gt;
]

.column.bg-main1[


.font_smaller[

### &amp;nbsp; &lt;br&gt;  &amp;nbsp;  
1. Give each node `\(i\)` a cluster label `\(z_i\)` and a degree-weight `\(\theta_i\)` (higher weight `\(\implies\)` more hyperedges involving that node).
2. For each tuple `\(R\)` of nodes, sample a random number of edges:
`$$a_R \sim \mathrm{Poisson}\left(\Omega(\mathbf{z}_R)\prod_{i \in R}\theta_i\right)$$`

Here, `\(\Omega\)` is an *affinity function* that encodes which combinations of groups are likely to form hyperedges. 
]

.footnote[
Bernoulli variant proposed by Ke et al (2019), 	
Community detection for hypergraph networks via regularized tensor power iteration, *arXiv:*:1909.06503
]
]

---

class: split-two
layout: false

.column[ 
  ### Hypergraph Stochastic Blockmodel
  &lt;img src="img/pure-fiction.png" width=90%&gt;
]

.column.bg-main1[

&lt;br&gt; &lt;br&gt; &lt;br&gt; 
## Today's Big Message

The generative approach to hypergraph clustering offers both .alert[scalable heuristics] and .alert2[fundamental theoretical insights]. 
]

---

layout: true
class: split-two middle 
 
.column[
  .split-three[ 
  .row.bg-main1[.content.vmiddle[.font_medium[Generative clustering with .alert[hypergraph blockmodels]].
  ]]    
  .row.bg-main2[.content.vmiddle[.font_medium[Scalable, greedy heuristics for .alert[large hypergraphs].] 
  ]] 
  .row.bg-main3[.content.vmiddle[.font_medium[.alert[Sparse thresholds] and eigenvector methods.] 
  ]]
]
] 

.column[.center[.stretch[
  {{content}} 
]]]

---

class: fade-row1-col1 fade-row3-col1 fade-row4-col1 fade-row5-col1

  &lt;img src="img/contact-clustering-excerpt.png" width=100%&gt;

---

class: split-two 
layout: false

.column.bg-main1[

&lt;br&gt; &lt;br&gt;
### Motivation 

Suppose we have some hypergraph Big Data® with suspected cluster structure.   

### Question

Can we do .alert[scalable] clustering with statistical foundations?


]

.column[.stretch[ 
  &lt;img src="img/hmod-paper.png" width=100%&gt;   
]]

---
class: split-50 bg-main1 
layout: false 
 
.row[ 
.split-three[
.column[&lt;br&gt;&lt;br&gt;
  &lt;img src="img/nate_portrait.jpeg" width=90%&gt; 
  ]
.column[&lt;br&gt;&lt;br&gt;
  &lt;img src="img/austin.jpg" width=90%&gt; 
]
.column[&lt;br&gt;&lt;br&gt;
  &lt;img src="img/phil_portrait.jpeg" width=90%&gt;   
] 

]
]
.row[ 
.split-three[
.column[&lt;br&gt;
  .font_large[.alert-no-bold[&lt;nobr&gt;Nate Veldt&lt;/nobr&gt;]]
  &lt;nobr&gt;Computer Science&lt;/nobr&gt; &lt;br&gt; Texas A&amp;M      
  .alert2[@n_veldt]
]  
.column[&lt;br&gt;
  .font_large[.alert-no-bold[&lt;nobr&gt;Austin Benson&lt;/nobr&gt;]]
   Computer Science &lt;br&gt; Cornell      
   .alert2[@austinbenson]
]
.column[&lt;br&gt;
  .font_large[.alert-no-bold[&lt;nobr&gt;Phil Chodrow&lt;/nobr&gt;]]
  &lt;nobr&gt;Mathematics&lt;/nobr&gt; &lt;br&gt; UCLA
  &lt;br&gt; .alert2[@PhilChodrow] &lt;br&gt;
]
]
]



---

class: split-two
layout: 

.column.bg-main1[
### The Affinity Function `\(\Omega\)`

&lt;br&gt; 

`$$a_R \sim \mathrm{Poisson}\left(\Omega(\mathbf{z}_R)\prod_{i \in R}\theta_i\right)$$`

`\(\Omega\)` controls how hyperedges form in response to node labels. 

Let's focus on the .alert[All-Or-Nothing] affinity.

This models the idea that edges form most frequently when nodes have the same labels. 


]

.column[

### &lt;br&gt;

&lt;br&gt; &lt;br&gt;

Let `\(e\)` be a hyperedge of size `\(k\)`: 

`$$\Omega(\mathbf{z}_e) = \begin{cases}
  \omega_{k1} &amp;\quad e \text{ has all same labels} \\ 
  \omega_{k0} &amp;\quad \text{otherwise}\;.  
\end{cases}$$`

&lt;br&gt;

`$$\Omega(\color{#ff5252}{\bullet} \color{#ff5252}{\bullet} \color{#ff5252}{\bullet}) &gt; \Omega(\color{#ff5252}{\bullet} \color{#ff5252}{\bullet} \color{#FFD046}{\bullet})= \Omega(\color{#ff5252}{\bullet} \color{#FFD046}{\bullet} \color{#6ec0de}{\bullet})\ldots$$` 

]

&lt;!-- ---

class: split-two
layout: false


.column.bg-main1[
  ## Maximum-Likelihood Inference

  &lt;br&gt;

  We only observe `\(H\)`. How do we learn the clusters `\(\mathbf{z}\)`?

  Let `\(P(H; \theta, \mathbf{z}, \omega)\)` be the probability of realizing a hypergraph `\(H\)` with parameters `\((\theta, \mathbf{z}, \omega)\)`. 

  .alert[Maximum-Likelihood Inference]: 

  `$$(\hat{\theta}, \hat{\mathbf{z}}, \hat{\omega}) = \text{argmax}_{\theta, \mathbf{z}, \omega} \log P(H; \theta, \mathbf{z}, \omega).$$` 
]

.column[
  
  &lt;br&gt; &lt;br&gt; &lt;br&gt;

  Some estimates can be approximated quickly:

&lt;br&gt; 
  **Degree Weights**

  `$$\hat{\theta}_i \approx\text{degree of node }i \equiv d_i$$`

  **Affinity Values** (requires estimate of `\(\mathbf{z}\)`)

.font_smaller[
  `$$\omega_{k1} \approx \frac{\text{# homogeneous hyperedges }}{\prod_{j} (\text{sum of degrees in cluster } j)}\;.$$`
]

.footnote[Approximations exact when all clusters are same size]

] --&gt;


---

## Estimating labels `\(\mathbf{z}\)`

With the All-Or-Nothing affinity, we can derive an objective function from a maximum-likelihood problem for our blockmodel: 

$$
Q \triangleq \sum_k \color{#ff5252}{\beta_k} \left[(\text{# homogeneous }k\text{-edges}) - \color{#21728f}{\gamma_k}\sum_j (\text{# of edges in cluster } j)^k\right]
$$

`\(\color{#ff5252}{\beta_k} \triangleq \log \omega_{k1} - \log \omega_{k0}\)`. &lt;br&gt;
`\(\color{#21728f}{\gamma_k} \triangleq \frac{1}{\beta_k}(\omega_{k1} - \omega_{k0})\)`.

**Maximum-Likelihood Problem**: find cluster labels `\(\mathbf{z}\)` to make `\(Q\)` large. 

 
.footnote[
   
Derivation follows Newman, "Equivalence between modularity optimization and maximum likelihood methods for community detection." *PRE*, 2016
  
Generalizes Kamiński et al., "Clustering via hypergraph modularity." *PLoS ONE*, 2019] 

---

class: split-two

.column.bg-main1[

### Hypergraph Maximum-Likelihood Louvain Algorithm

&lt;br&gt;

1. All nodes start in their own cluster. 
2. Greedily .alert[merge] nodes to maximize `\(Q\)`. 
3. Then, greedily merge .alert2[entire clusters] of nodes.  
4. Estimate parameters `\(\omega\)` and `\(\{\theta_i\}\)`.
5. Repeat!

- Extends Louvain algorithm for graphs.
- Lots of small tricks to make this fast. 



.footnote[Blondel et al. "Fast unfolding of communities in large networks." *J. Stat. Mech.*, 2008]
]

.column[ 
  
  &lt;br&gt;
  &lt;img src="img/louvain.png" width=100%&gt;
  
  .footnote[Image from Traag et al., "From Louvain to Leiden: guaranteeing well-connected communities," *Scientific Reports*, 2019]
]

---
background-image: url(img/performance.png)
background-size: contain

#### We can retrieve correlated partitions on synthetic hypergraphs of .alert[1M nodes].

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; 

Hypergraph Louvain is roughly as fast as baseline methods based on graph projections. 

---

### .alert[Empirical data]: school contact hypergraphs. 

&lt;br&gt; 
.center[&lt;img src="img/sociopatterns.jpg" width=70%&gt;]

Cluster labels are classes in a primary school and a high school (in France). 


.footnote[
Stehlé et al. (*PLoS ONE*, 2011) and Mastrandrea et al. (*PLoS ONE*, 2015)
]

---


background-image: url(img/contact-clustering.png)
background-size: contain

---

background-image: url(img/recovery_experiments.png)
background-size: contain

---

class: split-two

.column.bg-main1[
  
  ## Summing Up

  &lt;br&gt;

  The generative approach informs .alert[scalable algorithms] for clustering hypergraphs. 

  These algorithms .alert[inherit assumptions] from their generative models. 

  These algorithms can .alert[outperform graph-based methods] on social interaction data sets. 

]

.column[.stretch[ 
  &lt;img src="img/hmod-paper.png" width=100%&gt;   
]]

---

layout: true
class: split-two middle 
 
.column[
  .split-three[ 
  .row.bg-main1[.content.vmiddle[.font_medium[Generative clustering with .alert[hypergraph blockmodels]].
  ]]    
  .row.bg-main2[.content.vmiddle[.font_medium[Scalable, greedy heuristics for .alert[large hypergraphs].] 
  ]] 
  .row.bg-main3[.content.vmiddle[.font_medium[.alert[Sparse thresholds] and eigenvector methods.] 
  ]]
]
] 

.column[.center[.stretch[
  {{content}} 
]]]

---

class: fade-row1-col1 fade-row2-col1 fade-row4-col1 fade-row5-col1

&lt;img src="img/spectrum.png" width=75%&gt; 
&lt;img src="img/heatmap-exp-1.png" width=85%&gt; 

---

layout: false
class: split-two

.column.bg-main1[ 
  ### Sparsity

  &lt;br&gt;
  A hypergraph blockmodel is .alert[*sparse*] if `\(\Omega\)` is tuned so that 

  $$ \Omega(\mathbf{z}_R) = O(n^{1-\left|{R}\right|})\;. $$

  **Consequence**: \# edges attached to a node doesn't grow with the size of the hypergraph. 

  .alert[Intuition]: if the world's population doubled, the number of friends that you personally have might not change too much. 
]

.column[
  ### Fundamental Limits

  &lt;br&gt;
  In graphs, it turns out that there are sparse blockmodels for which algorithms can't even .alert[sometimes] find clusters that are even .alert2[correlated] with the correct ones.   

  
  &lt;br&gt;
  What about hypergraphs?

  .footnote[
    Decelle et al. (2011) Inference and phase transitions in the detection of modules in sparse networks, *Phys. Rev. Let.* 107.6: 065701
    &lt;br&gt; &lt;br&gt;
    Mossel et al. (2018) A proof of the blockmodel threshold conjecture, *Combinatorica*.  
  ]
  
]

---
class: split-50 bg-main1 
layout: false 
 
.row[ 
.split-three[
.column[&lt;br&gt;&lt;br&gt;
  &lt;img src="img/eikmeier-3.png" width=90%&gt; 
]
.column[&lt;br&gt;&lt;br&gt;
  &lt;img src="img/jamie_portrait.jpeg" width=90%&gt; 
  ]
.column[&lt;br&gt;&lt;br&gt;
  &lt;img src="img/phil_portrait.jpeg" width=90%&gt;   
] 

]
]
.row[ 
.split-three[
.column[&lt;br&gt;
  .font_large[.alert-no-bold[&lt;nobr&gt;Nicole Eikmeier&lt;/nobr&gt;]]
   Computer Science &lt;br&gt; Grinnell College      
   .alert2[@NicoleEikmeier]
]
.column[&lt;br&gt;
  .font_large[.alert-no-bold[&lt;nobr&gt;Jamie Haddock&lt;/nobr&gt;]]
  &lt;nobr&gt;Mathematics&lt;/nobr&gt; &lt;br&gt; Harvey Mudd College      
  .alert2[@jamie_hadd]
]  
.column[&lt;br&gt;
  .font_large[.alert-no-bold[&lt;nobr&gt;Phil Chodrow&lt;/nobr&gt;]]
  &lt;nobr&gt;Mathematics&lt;/nobr&gt; &lt;br&gt; UCLA
  &lt;br&gt; .alert2[@PhilChodrow] &lt;br&gt;
]
]
]

---

class: 

### A Testbed for Sparse Hypergraph Clustering

&lt;img src="img/detectability-setup.png" width=100%&gt;


---

### Greedy Methods

&lt;img src="img/detectability-louvain.png" width=100%&gt;

Greedy methods (from last time) fail in large regions of our testbed! Can we do better?

&lt;!-- ---

class: split-two
layout: false

.column.bg-main1[
  ## Belief Propagation...

&lt;br&gt;

  ...is the "cavity method" of statistical physics. 

  ...is an approximate method for learning graphical models. 

  ...is a discrete-time dynamical system.  

  ...is **very** expensive on hypergraphs. 
]

.column[

## &amp;nbsp;



Formally, iterate these updates to convergence: 
&lt;br&gt; 
`\begin{align}
\mu_{iR}^{(s)} &amp;\gets \frac{1}{Z_{iR}}\prod_{Q \in \binom{[n]}{|R|}\setminus R} \nu_{Qi}^{(s)} \\ 
\nu_{Ri}^{(s)} &amp;\gets \frac{1}{Z_{Ri}}\sum_{\mathbf{z}:z_i = s}P(a_R| \mathbb{z}_R)\prod_{j \in R\setminus i} \mu_{jR}^{(z_j)}
\end{align}`

.font_smaller[  
`\(\mu_{iR}^{(s)}\)` is "node `\(i\)`'s confidence that it belongs to cluster `\(s\)` based on other nodes in tuple `\(R\)`."

`\(Z_{iR}\)` is a normalization constant. 

`\(P(a_R|\mathbb{z}_R)\)` is our HSBM. 
]
] --&gt;

---

class: split-two

.column.bg-main1[

### The Belief-Propagation Jacobian


&lt;br&gt; 
.alert[Belief-propagation] is a method for learning probabilistic machine learning models, but it's very expensive on hypergraphs. 

&lt;br&gt;

We can approximate BP by computing eigenvectors of the .alert[Jacobian matrix], evaluated at an uninformative fixed point.  

Eigenvectors of the Jacobian (sometimes) give useful cluster information. 

]
.column[
  

### &amp;nbsp; 

&lt;br&gt; 
**Theorem (PSC, JH, NE '22)**: In a sparse HSBM, 

  `$$\mathcal{J} = \sum_{k = 1}^{\bar{k}} \mathbf{C}_k \otimes \mathbf{B}_k + O(n^{-1})\;,$$`

  - `\(\mathbf{C}_k\)` is a matrix of parameters that depends on the affinity function `\(\Omega\)`. 
  - `\(\mathbf{B}_k\)` is a matrix called the *Hashimoto operator* for edges of size `\(k\)`. 
  - `\(\otimes\)` is the matrix Kronecker product. 


.footnote[
  .alert2[Shown for graphs by]: &lt;br&gt; Krzakala et al. (2013)  Spectral redemption in clustering sparse networks, &lt;i&gt;PNAS&lt;/i&gt; 110 (52) 20935-20940
]
]

---
layout: false
class: split-two

.column.bg-main1[
## The Hashimoto Operator

&lt;br&gt;
The .alert[Hashimoto operator] `\(\color{#FFD046}{\mathbf{B}_k}\)` is a matrix that operates on *edge-node pairs*. 

Define `\((e_1, p_1) \rightarrow_k (e_2, p_2)\)`: 

- `\(p_1 \in e_1\)` and `\(p_2 \in e_2\)`
- `\(p_1 \in e_2 \setminus p_2\)`
- `\(e_1 \neq e_2\)`
- `\(\lvert e_2\rvert = k\)`. 

Then, 

.font_smaller[ .font_smaller[
`$$\mathbf{B}[(e_1, p_1), (e_2, p_2)] = \begin{cases} 1 &amp;\quad (e_1, p_1) \rightarrow_k (e_2, p_2) \\ 
0 &amp;\quad \text{otherwise.}\end{cases}$$`
]]]

.column[
&lt;br&gt;
&lt;img src="img/hypergraph-nonbacktracking.png" width=100%&gt;

"I can get to `\(p_2 \in e_2\)` from `\(e_1\)` by passing through `\(p_1\)`. I can get to `\(p_3 \in e_3\)` from `\(e_2\)` by passing through `\(p_2\)`..."

]

---
class: split-two
layout: false


.column.bg-main1[
## The Hashimoto Operator

&lt;br&gt; 
Popularized (for graphs) by Hashimoto, K. (1990), *Int. J. Math.* 

Important theorem for computation by Bass, H. (1992), *Int. J. Math.* 

Formulated for hypergraphs by Storm, C. K. (2006). *The Electronic Journal of Combinatorics*.

"Rediscovered" for hypergraphs by Angelini, M. C. et al. (2015), *Allerton Conference*.

]

.column[
&lt;br&gt;
&lt;img src="img/hypergraph-nonbacktracking.png" width=100%&gt;

"I can get to `\(p_2 \in e_2\)` from `\(e_1\)` by passing through `\(p_1\)`. I can get to `\(p_3 \in e_3\)` from `\(e_2\)` by passing through `\(p_2\)`..."
]

---

class: split-two

## An Ihara-Bass Theorem for the BP Jacobian

`\(\mathbf{J} = \sum_k \mathbf{C}_k\otimes\mathbf{B}_k \approx \mathcal{J}\)` can be a very large matrix `\(\implies\)` slow eigenvalue computations. 

**Theorem (PSC, JH, NE '21)**: Under mild conditions, if `\(\lambda\)` is an "interesting" eigenvalue of `\(\mathbf{J},\)` then `\(\lambda\)` is also an eigenvalue of the `\(2n\ell\bar{k} \times 2n\ell\bar{k}\)` matrix

.font_smaller[
`$$\mathbf{J}' = (\mathbf{G}\otimes \mathbf{I}_n) \left[\begin{matrix} 
\mathbf{0} &amp; \mathbf{I}_\ell \otimes \mathbb{D} \\ 
\mathbf{0} &amp; \mathbf{I}_\ell \otimes \mathbb{A}
\end{matrix}\right] - \bar{\mathbf{G}} \left[\begin{matrix} 
\mathbf{0} &amp; \mathbf{I}_\ell \otimes \mathbf{I}_{\bar{k}} \\ 
\mathbf{I}_\ell \otimes (\mathbf{K} - \mathbf{I}_{\bar{k}-1}) &amp; \mathbf{I}_\ell \otimes (\mathbf{K} - 2\mathbf{I}_{\bar{k}-1})
\end{matrix}\right] \otimes \mathbf{I}_n$$`
]

- `\(\ell\)` is the number of clusters and `\(\bar{k}\)` the number of distinct edge sizes. 
- `\(\mathbf{G}\)`, `\(\bar{\mathbf{G}}\)` hold statistical parameters
- `\(\mathbb{D}\)` is a degree operator,  `\(\mathbb{A}\)` is an adjacency operator,  and `\(\mathbf{K}\)` is a diagonal matrix containing the possible edge sizes.   

.footnote[
  Similar in spirit to a famous result by Bass (1992, *Int. J. Math*).  
]

---



class: split-two

.column.bg-main1[

### Belief-Propagation Spectral Clustering

&lt;br&gt; 

1. Start with a guess about `\(\mathbf{C}_k\)` and form `\(\mathbf{J}'\)`. 
2. Compute the .alert[leading eigenvectors] of `\(\mathbf{J}'\)` with real eigenvalues. 
3. For each eigenvector `\(\mathbf{v} = (\alpha, \beta)\)`, compute `\(u_{i\ell} = \mathbb{1}\left(\sum_{k = 1}^{\bar{k}} \alpha_{ik}^{(\ell)} &gt; 0\right)\)`. 
4. Use a .alert2[Euclidean clustering algorithm] (like `\(k\)`-means) in the space spanned by the vectors `\(\{\mathbf{u}\}\)`. 
5. Re-estimate `\(\mathbf{C}_k\)` and repeat...

]



.column[.vmiddle[.center[

&lt;img src="img/PCA-synthetic.png" width=90%&gt; 

]]]






---

background-image: url(img/algorithm-demo.png)
background-size: contain

### Belief-Propagation Spectral Clustering



&lt;!-- ---

### Linear algebra for faster computation

`\(\mathbf{J}\)` is a *really* big matrix; eigencomputations are expensive.  

**Theorem (PSC, JH, NE '21)**: Under mild conditions, the "interesting" eigenvalues of `\(\mathbf{J}\)` are also eigenvalues of the (smaller) matrix

`$$\mathbf{J}' = (\mathbf{G}\otimes \mathbf{I}_n) \left[\begin{matrix} 
\mathbf{0} &amp; \mathbf{I}_\ell \otimes \mathbb{D} \\ 
\mathbf{0} &amp; \mathbf{I}_\ell \otimes \mathbb{A}
\end{matrix}\right] - \bar{\mathbf{G}} \left[\begin{matrix} 
\mathbf{0} &amp; \mathbf{I}_\ell \otimes \mathbf{I}_{\kappa } \\ 
\mathbf{I}_\ell \otimes (\mathbf{K} - \mathbf{I}_{\kappa}) &amp; \mathbf{I}_\ell \otimes (\mathbf{K} - 2\mathbf{I}_{\kappa})
\end{matrix}\right] \otimes \mathbf{I}_n$$`

.font_smaller[.font_smaller[
- `\(\ell\)` is the number of groups
- `\(\mathbf{G}\)`, `\(\bar{\mathbf{G}}\)` are matrices holding statistical parameters. 
- `\(\kappa\)` is the number of distinct edge sizes, `\(n\)` is the number of nodes. 
- `\(\mathbb{A} \in \mathbb{R}^{\kappa n\times \kappa n}\)` collects adjacency information for each hyperedge size.
- `\(\mathbb{D} \in \mathbb{R}^{\kappa n\times \kappa n}\)` collects node degrees for each hyperedge size. 
- `\(\mathbf{K} \in \mathbb{R}^{\kappa \times \kappa }\)` lists possible edge sizes. 
- `\(\mathbf{I}_{\ell} \in \mathbb{R}^{\ell\times \ell}\)` is the matrix identity of size `\(\ell\)`. 
- `\(\otimes\)` is the Kronecker product. 
]] --&gt;

---
### *Flashback: Greedy Methods*

&lt;img src="img/detectability-louvain.png" width=100%&gt;

---

### BP Jacobian Spectral Algorithm

.center[
&lt;img src="img/heatmap-exp-1-no-curve.png" width=80%&gt;
]

---

### BP Jacobian Spectral Algorithm

.center[
&lt;img src="img/heatmap-exp-1.png" width=80%&gt;
]

---

class: split-two

.column.bg-main1[
### Detectability (Algorithmic)

.font_smaller[
**Conjecture**: In a 2-group blockmodel with edge sizes `\(k_1,k_2,\ldots\)` and `\(c_k\)` edges of size `\(k\)` per node, .alert[spectral clustering] fails to detect clusters in the ellipsoid with centroid `\((x_{k_1},x_{k_2},\ldots)\)` and radii `\((r_{k_1},r_{k_1}\ldots)\)`, where: 


$$
`\begin{align}
x_k &amp;= \frac{1-a_k}{2-a_k} d \\ 
r_k &amp;= \frac{\sqrt{(k-1)c_k}}{2-a_k} \\
a_k &amp;= \frac{1-2^{2-k}}{1-2^{1-k}}\;.
\end{align}`
$$
]

.footnote[Proof requires controlling spectrum of Hashimoto operator, possibly generalizing approach used in: 

Bordenave et al. (2018): Non-backtracking spectrum of random graphs: community detection and non-regular Ramanujan graphs. *Annals of Probability*.
]

]

.column[.stretch[
.center[ &lt;br&gt; &lt;br&gt; &lt;br&gt;
&lt;img src="img/4-heatmaps.png" width=100%&gt;
]
]
]

---

class: split-two

.column.bg-main1[
### Detectability (Fundamental)

.font_smaller[
**Conjecture**: In a 2-group blockmodel with edge sizes `\(k_1,k_2,\ldots\)` and `\(c_k\)` edges of size `\(k\)` per node, .alert[any algorithm] fails to detect clusters in the ellipsoid with centroid `\((x_{k_1},x_{k_2},\ldots)\)` and radii `\((r_{k_1},r_{k_1}\ldots)\)`, where: 


$$
`\begin{align}
x_k &amp;= \frac{1-a_k}{2-a_k} d \\ 
r_k &amp;= \frac{\sqrt{(k-1)c_k}}{2-a_k} \\
a_k &amp;= \frac{1-2^{2-k}}{1-2^{1-k}}\;.
\end{align}`
$$
]

.footnote[Generalizes recent theorem for graph blockmodels: 

Mossel et al. (2018) A proof of the blockmodel threshold conjecture, *Combinatorica*.  
]

]

.column[.stretch[
.center[ &lt;br&gt; &lt;br&gt; &lt;br&gt;
&lt;img src="img/4-heatmaps.png" width=100%&gt;
]
]
]


---

class: split-two
layout: false

.column.bg-main1[

## Summing Up

&lt;br&gt;

Belief-propagation spectral clustering can help us form conjectures about when detecting clusters is .alert[even possible].  

Proving these conjectures is likely to require some powerful machinery from random matrix theory and discrete probability. 

]

.column[.stretch[
.center[ &lt;br&gt; &lt;br&gt; &lt;br&gt;
&lt;img src="img/4-heatmaps-2.png" width=100%&gt;
]
]
]

---

class: bg-main1

## Today's Big Message

The generative approach to hypergraph clustering offers both .alert[scalable heuristics] and .alert2[fundamental theoretical insights]. 

### Lots more to do!  

1. Scalable heuristics for more general affinity functions `\(\Omega\)`. 
2. Prove those detectability conjectures. 
3. More complex models:
  - Weighted hypergraphs
  - Hypergraphs with node metadata
  - Dynamic interactions (timestamped edges)
  - Etc



---

class: split-two

.column.bg-main1[
# **Thanks!**

.row[ 
.split-two[
.column[.lil-stretch[&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; 
  &lt;img src="img/nate.jpg" width=80%&gt; 
  .alert[Nate Veldt] &lt;br&gt; Texas A&amp;M
  ]
  ]
.column[
  .lil-stretch[&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
  &lt;img src="img/austin.jpg" width=80%&gt; 
  .alert[Austin Benson] &lt;br&gt; Cornell 
  ]
]]]

&lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt; &lt;br&gt;
&lt;b&gt;PSC&lt;/b&gt;, N. Veldt, A. R. Benson, (2021). Generative hypergraph clustering: from blockmodels to modularity, &lt;i&gt;Science Advances&lt;/i&gt;, 7:eabh1303
]

.column[ 
# &amp;nbsp;   

.row[ 
.split-two[
.column[.lil-stretch[&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt; 
  &lt;img src="img/eikmeier-3.png" width=80%&gt; 
  .alert[**Nicole Eikmeier**] &lt;br&gt; Grinnell 
  ]
  ]
.column[
  .lil-stretch[&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
  &lt;img src="img/jamie_portrait.jpeg" width=80%&gt; 
  .alert[**Jamie Haddock**] &lt;br&gt; Harvey Mudd 
  ]
]]]

&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
&lt;b&gt;PSC&lt;/b&gt;, N. Eikmeier, J. Haddock, (2022). Nonbacktracking spectral clustering of nonuniform hypergraphs, &lt;i&gt;In preparation&lt;/i&gt;
]

---

class: bg-main1 middle

# Bonus Content (extra slides)

---

layout: false
class: split-two

.column.bg-main1[
  ### A Note on Expectations
  
  &lt;br&gt;

  Nontrivial clustering problems almost always have multiple, .alert[competing] answers. 

  When a unique optimal answer exists, it is usually .alert[NP-hard] to compute. 

  So, we usually aim for .alert2[heuristics] with interpretable properties. 

  .footnote[
    Good et al. (2010), "The performance of modularity maximization in practical contexts", *PRE* 81.4:046106
    &lt;br&gt; &lt;br&gt;
    Brandes et al. (2007), "On finding graph clusterings with maximum modularity," *WG'07*:121-132 
  ]

]
.column[.content.vmiddle[.stretch[
  &lt;img src="img/detection-1.png" width=100%&gt;
]]]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:10",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
